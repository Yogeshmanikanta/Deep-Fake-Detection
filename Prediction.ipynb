{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a5165ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/Dataset_Folder/real_and_fake_face\\\\training_real'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m\n\u001b[0;32m     15\u001b[0m train_dat \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     16\u001b[0m     rescale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m,\n\u001b[0;32m     17\u001b[0m     width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[0;32m     21\u001b[0m )\n\u001b[0;32m     23\u001b[0m test_dat \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     24\u001b[0m     rescale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m\n\u001b[0;32m     25\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43mimg_w\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbinary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m     32\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m test_gen \u001b[38;5;241m=\u001b[39m test_dat\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     35\u001b[0m     test_data,\n\u001b[0;32m     36\u001b[0m     target_size \u001b[38;5;241m=\u001b[39m (img_h,img_w),\n\u001b[0;32m     37\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m batch_size,\n\u001b[0;32m     38\u001b[0m     class_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m )\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m#building a nn\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:1649\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1562\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1563\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1564\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1578\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1579\u001b[0m ):\n\u001b[0;32m   1580\u001b[0m     \u001b[38;5;124;03m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1581\u001b[0m \n\u001b[0;32m   1582\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;124;03m        and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1653\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1661\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1662\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1663\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1665\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1666\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\src\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[0;32m    564\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/Dataset_Folder/real_and_fake_face\\\\training_real'"
     ]
    }
   ],
   "source": [
    "from cgi import test\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "#tf.keras.preprocessing.image.ImageDataGenerator\n",
    "dir = \"/content/Dataset_Folder/real_and_fake_face\"\n",
    "train_data = os.path.join(dir,'training_real')  # <base_dir,'dir to be conside'>\n",
    "test_data = os.path.join(dir,'testing_fake')\n",
    "\n",
    "img_h,img_w =150,150\n",
    "batch_size = 32\n",
    "\n",
    "#processing of these images\n",
    "\n",
    "train_dat = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    rotation_range=40,\n",
    "    zoom_range=0.2,\n",
    ")\n",
    "\n",
    "test_dat = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")\n",
    "\n",
    "train_gen = train_dat.flow_from_directory(\n",
    "    train_data,\n",
    "    target_size = (img_h,img_w),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "test_gen = test_dat.flow_from_directory(\n",
    "    test_data,\n",
    "    target_size = (img_h,img_w),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'binary'\n",
    ")\n",
    "\n",
    "#building a nn\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (img_h,img_w,3)),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (img_h,img_w,3)),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),activation = 'relu',input_shape = (img_h,img_w,3)),\n",
    "    tf.keras.layers.MaxPool2D((2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512,activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "#compile the output\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "#training the model\n",
    "\n",
    "tr=model.fit(train_gen,\n",
    "               steps_per_epoch = 10,\n",
    "               epochs = 10,\n",
    "               validation_data = test_gen,\n",
    "               validation_steps = 10\n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531048ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model.save('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "795af3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06d63367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Class : Fake\n",
      "Accuracy : 99.99982118606567\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "from PIL import Image, ImageOps  # Install pillow instead of PIL\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"keras_Model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"labels.txt\", \"r\").readlines()\n",
    "\n",
    "# Create the array of the right shape to feed into the keras model\n",
    "# The 'length' or number of images you can put into the array is\n",
    "# determined by the first position in the shape tuple, in this case 1\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "image = Image.open(\"Dataset_Folder/real_and_fake_face/training_fake/easy_152_0011.jpg\")\n",
    "\n",
    "# Resizing the image to be at least 224x224 and then cropping from the center\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.Resampling.LANCZOS)\n",
    "\n",
    "# Turn the image into a numpy array\n",
    "image_array = np.asarray(image)\n",
    "\n",
    "# Normalize the image\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.5) - 1\n",
    "\n",
    "# Load the image into the array\n",
    "data[0] = normalized_image_array\n",
    "\n",
    "# Predicts the model\n",
    "prediction = model.predict(data)\n",
    "index = np.argmax(prediction)\n",
    "class_name = class_names[index]\n",
    "accuracy = prediction[0][index]\n",
    "\n",
    "# Print Prediction and Accuracy\n",
    "print(\"Class :\", class_name[2:], end=\"\")\n",
    "print(\"Accuracy :\", accuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd79ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
